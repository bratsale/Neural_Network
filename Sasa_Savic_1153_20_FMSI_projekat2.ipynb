{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalne metode u softverskom inženjeringu\n",
    "## Neuronske mreže i LightGBM, projekat br. 2\n",
    "### Saša Savić 1153/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neuronska mreža"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.4139 - Precision: 0.3168, Recall: 0.2139\n",
      "Epoch 2/10 - Loss: 0.2761 - Precision: 0.6338, Recall: 0.1798\n",
      "Epoch 3/10 - Loss: 0.1206 - Precision: 0.8413, Recall: 0.2448\n",
      "Epoch 4/10 - Loss: 0.0804 - Precision: 0.7997, Recall: 0.3420\n",
      "Epoch 5/10 - Loss: 0.0592 - Precision: 0.8244, Recall: 0.3906\n",
      "Epoch 6/10 - Loss: 0.0427 - Precision: 0.8261, Recall: 0.4417\n",
      "Epoch 7/10 - Loss: 0.0307 - Precision: 0.7750, Recall: 0.4666\n",
      "Epoch 8/10 - Loss: 0.0215 - Precision: 0.8120, Recall: 0.4933\n",
      "Epoch 9/10 - Loss: 0.0136 - Precision: 0.8000, Recall: 0.5103\n",
      "Epoch 10/10 - Loss: 0.0099 - Precision: 0.7676, Recall: 0.4976\n",
      "Best Precision: 0.8413\n",
      "Best Recall: 0.2448\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# učitavanje podataka (1000 podataka, iz nekog rezloga crash-uje kernel ako stavim više), standardizacija...\n",
    "\n",
    "rcvdata = fetch_rcv1()\n",
    "X = rcvdata.data[0:1000].toarray()\n",
    "Y = rcvdata.target[0:1000].toarray()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)  \n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Definicija modela, slojevi n. mreža, funkcija greške\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Network, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 512)\n",
    "        self.layer2 = nn.Linear(512, 1024)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer3 = nn.Linear(1024, 512)\n",
    "        self.layer4 = nn.Linear(512, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()  # dodajemo sigmoid funkciju ovdje!\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)  \n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.sigmoid(self.layer4(x))  # primjena sigmoida na izlaz\n",
    "        return x\n",
    "\n",
    "# kreiranje modela\n",
    "input_size = X_train_tensor.shape[1]\n",
    "output_size = Y_train_tensor.shape[1]\n",
    "model = Network(input_size, output_size)\n",
    "\n",
    "criterion = nn.BCELoss()  # obzirom da koristimo sigmoid u forward metodi, koristimo BCELoss\n",
    "optimizer = optim.Adam(model.parameters()) # koristimo Adam za optimizaciju\n",
    "\n",
    "# obucavanje modela\n",
    "def train_model(model, train_loader, test_loader, epochs=10):\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for X_batch, Y_batch in train_loader:\n",
    "            optimizer.zero_grad()  # moramo resetovati gradijent\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, Y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        # Evaluacija \n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, Y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                preds = (outputs > 0.5).float()\n",
    "                all_preds.append(preds)\n",
    "                all_labels.append(Y_batch)\n",
    "        \n",
    "        all_preds = torch.cat(all_preds)\n",
    "        all_labels = torch.cat(all_labels)\n",
    "\n",
    "        precision = precision_score(all_labels.cpu().numpy(), all_preds.cpu().numpy(), average='micro', zero_division=0)\n",
    "        recall = recall_score(all_labels.cpu().numpy(), all_preds.cpu().numpy(), average='micro', zero_division=0)\n",
    "\n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss/len(train_loader.dataset):.4f} - Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "    \n",
    "    torch.save(best_model_state, 'best_model.pth')\n",
    "    return best_precision, best_recall\n",
    "\n",
    "# Obučavanje modela i ispis najboljeg modela\n",
    "best_precision, best_recall = train_model(model, train_loader, test_loader, epochs=10)\n",
    "\n",
    "print(f'Best Precision: {best_precision:.4f}')\n",
    "print(f'Best Recall: {best_recall:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-26 22:09:42,217] A new study created in memory with name: no-name-bd8e631c-bd34-42ec-b2b0-be56126b1eb7\n",
      "[I 2024-08-26 22:09:44,146] Trial 0 finished with value: 0.392 and parameters: {'learning_rate': 0.09087492225724444, 'num_leaves': 185, 'max_depth': 12, 'feature_fraction': 0.6584634539263836, 'bagging_fraction': 0.6926363359711982, 'bagging_freq': 6, 'lambda_l1': 9.470097529414828, 'lambda_l2': 3.2776989773176757}. Best is trial 0 with value: 0.392.\n",
      "[I 2024-08-26 22:09:46,224] Trial 1 finished with value: 0.594 and parameters: {'learning_rate': 0.06806684428651762, 'num_leaves': 87, 'max_depth': 8, 'feature_fraction': 0.7544514463951049, 'bagging_fraction': 0.6483956931185013, 'bagging_freq': 7, 'lambda_l1': 0.5667798653401083, 'lambda_l2': 7.674348548898353}. Best is trial 1 with value: 0.594.\n",
      "[I 2024-08-26 22:09:48,176] Trial 2 finished with value: 0.61 and parameters: {'learning_rate': 0.07568586121376299, 'num_leaves': 183, 'max_depth': 8, 'feature_fraction': 0.9120880376799133, 'bagging_fraction': 0.4768025137209355, 'bagging_freq': 7, 'lambda_l1': 1.0429400679855008, 'lambda_l2': 2.0841114886155925}. Best is trial 2 with value: 0.61.\n",
      "[I 2024-08-26 22:09:51,196] Trial 3 finished with value: 0.484 and parameters: {'learning_rate': 0.029968184885728263, 'num_leaves': 140, 'max_depth': 13, 'feature_fraction': 0.4082075229980732, 'bagging_fraction': 0.8876046392588658, 'bagging_freq': 1, 'lambda_l1': 5.1402071291620075, 'lambda_l2': 2.092847506261339}. Best is trial 2 with value: 0.61.\n",
      "[I 2024-08-26 22:09:52,826] Trial 4 finished with value: 0.444 and parameters: {'learning_rate': 0.08984312319350451, 'num_leaves': 237, 'max_depth': 10, 'feature_fraction': 0.652939574539527, 'bagging_fraction': 0.603694798210311, 'bagging_freq': 7, 'lambda_l1': 7.006519359398061, 'lambda_l2': 0.5404928556218231}. Best is trial 2 with value: 0.61.\n",
      "[I 2024-08-26 22:09:54,699] Trial 5 finished with value: 0.448 and parameters: {'learning_rate': 0.08438519944852374, 'num_leaves': 131, 'max_depth': 10, 'feature_fraction': 0.9894162591658667, 'bagging_fraction': 0.9565452508046315, 'bagging_freq': 5, 'lambda_l1': 8.879797179025498, 'lambda_l2': 4.02633737015787}. Best is trial 2 with value: 0.61.\n",
      "[I 2024-08-26 22:09:56,353] Trial 6 finished with value: 0.418 and parameters: {'learning_rate': 0.044061019031932665, 'num_leaves': 176, 'max_depth': 15, 'feature_fraction': 0.6411466747975243, 'bagging_fraction': 0.7799609374772694, 'bagging_freq': 6, 'lambda_l1': 8.893472289702828, 'lambda_l2': 1.5944120198962513}. Best is trial 2 with value: 0.61.\n",
      "[I 2024-08-26 22:09:57,887] Trial 7 finished with value: 0.4 and parameters: {'learning_rate': 0.09953874875925577, 'num_leaves': 201, 'max_depth': 15, 'feature_fraction': 0.7830920960797838, 'bagging_fraction': 0.6118225157422217, 'bagging_freq': 4, 'lambda_l1': 9.017043158876895, 'lambda_l2': 6.4560516108203165}. Best is trial 2 with value: 0.61.\n",
      "[I 2024-08-26 22:10:00,281] Trial 8 finished with value: 0.53 and parameters: {'learning_rate': 0.02469793102328422, 'num_leaves': 218, 'max_depth': 6, 'feature_fraction': 0.7370239691780451, 'bagging_fraction': 0.7710499672172403, 'bagging_freq': 2, 'lambda_l1': 0.33828007875699245, 'lambda_l2': 5.59996464088695}. Best is trial 2 with value: 0.61.\n",
      "[I 2024-08-26 22:10:04,237] Trial 9 finished with value: 0.568 and parameters: {'learning_rate': 0.009523228577331358, 'num_leaves': 121, 'max_depth': 11, 'feature_fraction': 0.48893133974776914, 'bagging_fraction': 0.8959951342210695, 'bagging_freq': 3, 'lambda_l1': 0.03108939844546346, 'lambda_l2': 0.2711001783712662}. Best is trial 2 with value: 0.61.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.61\n",
      "  Params: \n",
      "    learning_rate: 0.07568586121376299\n",
      "    num_leaves: 183\n",
      "    max_depth: 8\n",
      "    feature_fraction: 0.9120880376799133\n",
      "    bagging_fraction: 0.4768025137209355\n",
      "    bagging_freq: 7\n",
      "    lambda_l1: 1.0429400679855008\n",
      "    lambda_l2: 2.0841114886155925\n",
      "Best model - Precision: 0.3174, Recall: 0.2958, Accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikingg89/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Izbacili smo ponovo korištenje test-train splita, dobijeni bolji rezultati metrika evaluacije na kraju\n",
    "\n",
    "# Pretvaranje Y_train i Y_test u numeričke oznake klasa, kompatabilno sa LightGBM-om\n",
    "Y_train_np = np.argmax(Y_train, axis=1)\n",
    "Y_test_np = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Definisanje za pretragu hiperparametara\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_class': len(np.unique(Y_train_np)),  # Broj klasa!\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 15),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0),\n",
    "        'verbosity': -1\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**param)\n",
    "    model.fit(X_train, Y_train_np)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test_np, Y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('  Value: {}'.format(trial.value))\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n",
    "\n",
    "best_params = trial.params\n",
    "best_model = lgb.LGBMClassifier(**best_params)\n",
    "best_model.fit(X_train, Y_train_np)\n",
    "\n",
    "# Evaluacija\n",
    "Y_pred = best_model.predict(X_test)\n",
    "precision = precision_score(Y_test_np, Y_pred, average='macro')\n",
    "recall = recall_score(Y_test_np, Y_pred, average='macro')\n",
    "accuracy = accuracy_score(Y_test_np, Y_pred)\n",
    "\n",
    "print(f'Best model - Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
